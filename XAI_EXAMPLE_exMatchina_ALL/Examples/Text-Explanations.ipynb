{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcCy2ACiLL8f"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from exmatchina import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5l_UpWOHw01J"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "class_names = ['negative', 'positive']\n",
    "\n",
    "class_dict = {\n",
    "    'negative': 0,\n",
    "    'positive': 1,\n",
    "}\n",
    "\n",
    "inv_class_dict = {v: k for k, v in class_dict.items()}\n",
    "\n",
    "## These are the randomly generated indices \n",
    "\n",
    "all_idx = np.array([  9528,  11977,  17734,  18431,  19988])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eq_UjQBgxKAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of unique tokens found (in train data): 283625\n"
     ]
    }
   ],
   "source": [
    "raw_images_train = pd.read_pickle('data/text/X_train_df')\n",
    "raw_images_test = pd.read_pickle('data/text/X_test_df')\n",
    "\n",
    "with open('data/text/tokenizer.pickle', 'rb') as f:\n",
    "    tk = pickle.load(f)\n",
    "\n",
    "word_index = tk.word_index\n",
    "print('[INFO] Number of unique tokens found (in train data):', len(word_index))\n",
    "\n",
    "id_to_word = {value:key for key,value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLfGlYMU99G1"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "MAX_SEQ_LEN = 40\n",
    "EMB_DIM = 100\n",
    "\n",
    "# Returns the raw text of the review\n",
    "def get_review(x):\n",
    "    return ' '.join(id_to_word[id] for id in x if id != 0)\n",
    "\n",
    "def get_train_review(idx):\n",
    "    return (raw_images_train['Texts'][idx]).replace(\"&amp;\",\"&\").replace('&quot;','\"').replace('&lt;','<').replace('_','@')\n",
    "\n",
    "def get_test_review(idx):\n",
    "    return raw_images_test['Texts'][idx].replace(\"&amp;\",\"&\").replace('&quot;','\"').replace('&lt;','<').replace('_','@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "T1iWGXGLy7Q9",
    "outputId": "99ab8f00-42d3-438a-fc81-0989d5427323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280000, 40)\n",
      "(320000, 40)\n",
      "(1280000, 1)\n",
      "(320000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/text/X_train.npy')\n",
    "X_test = np.load('data/text/X_test.npy')\n",
    "\n",
    "y_train = np.load('data/text/y_train.npy')\n",
    "y_test = np.load('data/text/y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "-h88vhkc2r7k",
    "outputId": "6a844cc5-0e2d-4e24-9acb-f2468f7fcff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Embedding (Embedding)        (None, 40, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 40, 100)           0         \n",
      "_________________________________________________________________\n",
      "Conv_1 (Conv1D)              (None, 40, 512)           154112    \n",
      "_________________________________________________________________\n",
      "Max_1 (MaxPooling1D)         (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv1D)              (None, 20, 256)           393472    \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv1D)              (None, 20, 15)            11535     \n",
      "_________________________________________________________________\n",
      "Flatten_1 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 20)                6020      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,565,160\n",
      "Trainable params: 2,565,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('trained_models/text.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExMatchina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting activations...\n",
      "Getting labels...\n",
      "Generating activation matrix...\n"
     ]
    }
   ],
   "source": [
    "selected_layer = 'Flatten_1'\n",
    "\n",
    "exm = ExMatchina(model=model, layer=selected_layer, examples=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "9528 REVIEW: I dont know.. they said it will arrived 1-2 days,, in fact malah suka lewat, even 4 days,,\n",
      "9528 Example 1: Just missing each other by a week or so.  Have fun while you're in Cancun!\n",
      "9528 Example 2: Oh no  Hope everything goes Ok. Will have lots of positive thoughts for you guys.\n",
      "9528 Example 3: its not fair  mourning for south east asian blockheads..thx 4 share it with us gal\n",
      "\n",
      "=====\n",
      "\n",
      "negative\n",
      "11977 REVIEW: Those of you that know me, say a prayer for my Dad, his heart is broken...\n",
      "11977 Example 1: so i went today to pick up that lap top... my friend talked me out of it  i came home dissapointed\n",
      "11977 Example 2: Yeah its totally crazy. I have friends that are firefighters for Grand Blanc and Mundy. I hear lots of stuff. Real sad.\n",
      "11977 Example 3: Ok, so I got up on my one day off and my sister is apparently sick....  .....\n",
      "\n",
      "=====\n",
      "\n",
      "positive\n",
      "17734 REVIEW: I love being accused of using an aimbot, it's just so flattering.\n",
      "17734 Example 1: well good feedback means so much more,in my opinion. Congratulations\n",
      "17734 Example 2: its fine  i will tomorrow shall be a better day, thankyou.\n",
      "17734 Example 3: Thats ironic cuz I was just watching that. It's really good\n",
      "\n",
      "=====\n",
      "\n",
      "negative\n",
      "18431 REVIEW: you keep disappearing and it makes me a sad panda\n",
      "18431 Example 1: the end of him and me. very sad ending.\n",
      "18431 Example 2: Of to work, going to be a very sad day\n",
      "18431 Example 3: yeah so its been half an hour and still no reply\n",
      "\n",
      "=====\n",
      "\n",
      "positive\n",
      "19988 REVIEW: The road to success is dotted with so many parking places. Agree? Good Tuesday morning Twitter Universe!\n",
      "19988 Example 1: Barack Obama's speech rocked! I've never seen him smile so much. He loves ASU.\n",
      "19988 Example 2: Its so smooth i just wanna pet it - allison. Haha gotta love science class\n",
      "19988 Example 3: She sounds strong-willed and determined.  Can't she just become an engineer?  Without the navy\n",
      "\n",
      "=====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_idx in all_idx:\n",
    "    test_input = X_test[test_idx]\n",
    "    \n",
    "    to_explain = np.expand_dims(test_input, axis=0)\n",
    "    class_pred = np.rint(model.predict(to_explain)[0])\n",
    "    print(inv_class_dict[class_pred[0]])\n",
    "    \n",
    "    (examples, indices) = exm.return_nearest_examples(test_input, 3)\n",
    "    \n",
    "    review = get_test_review(test_idx)\n",
    "    # print(\"REVIEW RAW\", review)\n",
    "    review = get_test_review(test_idx)\n",
    "    review_1 = get_train_review(indices[0])\n",
    "    review_2 = get_train_review(indices[1])\n",
    "    review_3 = get_train_review(indices[2])\n",
    "\n",
    "    print(test_idx, \"REVIEW:\", review)\n",
    "    print(test_idx, \"Example 1:\", review_1)\n",
    "    print(test_idx, \"Example 2:\", review_2)\n",
    "    print(test_idx, \"Example 3:\", review_3)\n",
    "    print(\"\\n=====\\n\")\n",
    "#     draw_txt(review, \"text-\" + str(test_idx))\n",
    "#     draw_txt( \"SIMILAR TWEET #1 (\" + sentiment + \"):\\n\" +\n",
    "#              review_1 + \"\\n\\nSIMILAR TWEET #2 (\" + sentiment + \"):\\n\" +\n",
    "#              review_2 + \"\\n\\nSIMILAR TWEET #3 (\" + sentiment + \"):\\n\" + \n",
    "#              review_3 , \"text-\"+ str(test_idx) +\"-example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text-SHAP-LIME-Anchor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
